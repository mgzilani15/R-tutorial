---
title: "lda"
author: "zilani"
date: "16 October 2018"

output: 
    html_document:
      theme: flatly 
      highlight: tango
      toc: true
      toc_float: true
---

<style>
h3 {
  color: white;
  background-color: #44546a;
  text-indent: auto; 
</style>


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Library
```{r}
library(ISLR)
library(MASS)
library(caret)
set.seed(1)
source("functions_w6.R")
library(e1071)
library(mlbench)
library(class)
source("functions_w6.R")
```

**#########################################################################################**

# lda smarket data 

**### test train split and build the model ----------------------------------------------**



```{r}
# using the ISLR data of Smarket to classify and analysis LDA
# here we will examine the direction whether it is going up/down from the variable Direction
# this can be done by using the train and test data
# LDA is good while there are more than 2 classes


df<-Smarket

# structure of data frame
str(df)

# Test train split way-2
train=sample(1:nrow(df), nrow(df)/3)
datatest <- df[train, ]
datatrain  <- df[-train, ]

# apply the lda method to deside the direction with the train data
ldafit<-lda(Direction~., data=datatrain)

# call the model
ldafit


# predicting the model and display with test data
ldapred<-predict(ldafit, datatest)

#confussion matrix will be get from the table of LDA
ldapredclass<-ldapred$class
table(ldapredclass,datatest$Direction)

# accuricy of predecting Directions way-1
# in here predection accuricy is 97%
mean(ldapredclass==datatest$Direction)*100

```


**#### Build a LDA model using all the variable train function (smarket data)**

```{r}

LDA1 <- train(Direction ~.,
                     data = datatrain,
                     method = "lda",
                     trControl = trainControl(method = "repeatedcv", 
                                              repeats = 5))


## Print diagnostic and summary information and statistics fo the model 
LDA1
summary(LDA1)
LDA1$finalModel
```


**#########################################################################################**

# LDA (iris)

**### test train split and build the model and prediction----------------------------------------------**


```{r}

# we know that iris have 3 class which is good for LDA
# using all of the variables we will determine the class of species
# in this case we will use the train and test spliting of the data
# here there are two different way of spliting the data in R
#

dim(iris)
#head(iris)

# test train split way-1
  #library(caret)
  #set.seed(1)
  #inTrain <- createDataPartition(iris$Species, p = .6)[[1]]
  #dataTrain <- iris[ inTrain, ]
  #dataTest  <- iris[-inTrain, ]

# Test train split way-2
train=sample(1:nrow(iris), nrow(iris)/3)
dataTest <- iris[train, ]
dataTrain  <- iris[-train, ]

# using this training data lets buid the model
# and see the result
fit=lda(Species~., data=dataTrain)
fit

# predection with the test data with the model fit
# calculate the predected class
# confussion matrix with the actual value of test data

pred<-predict(fit,dataTest)
predclass<-pred$class
table(predclass, dataTest$Species)

# persentage of predecting in the test data way-1
# where we can see predection accuricy is 97%
mean(predclass==dataTest$Species)

# calculate classification accuracy (in percentage %) way-2
sum(predclass==dataTest$Species) / nrow(dataTest) * 100
```

**#########################################################################################**

# lda (Ionosphere) data

**#### using 10 fold cross Validation ----------------------------------------------**


```{r}
data(Ionosphere)
df <- Ionosphere
df <- df[,-2]
df <- df[,-1]


# apply 10-fold cross-validation
fold <- createFolds(df$Class, k=10)

lda.TP <- lda.TN <- lda.FP <- lda.FN <- c()

for(i in 1:length(fold)){

    # true label for fold i
    truth <- df$Class[fold[[i]]]
    
    lda.model <- lda(Class~., data=df)
    
    pred.probs <- predict(lda.model, newdata=df[fold[[i]],-33])$posterior[,"good"]
    preds <- ifelse(pred.probs > 0.5, "good", "bad")

    lda.TP <- c(lda.TP, sum((truth == preds)[truth == "good"]))
    lda.TN <- c(lda.TN, sum((truth == preds)[truth == "bad"]))
    lda.FP <- c(lda.FP, sum((truth != preds)[truth == "bad"]))
    lda.FN <- c(lda.FN, sum((truth != preds)[truth == "good"]))
 
}
evaluate(lda.TN, lda.FP, lda.TP,lda.FN)

```

**#########################################################################################**

# lda breast-w data 

```{r}
# read in tab-delimited data file
breastCancerFull <- read.delim("breast-w.txt", head=TRUE)
str(breastCancerFull)

```

**#### test train split 80/20 ----------------------------------------------**

```{r}
# Load the "caret" package. This package is used to partition data, training and test classification models etc.
library(caret)
set.seed(1)
inTrain <- createDataPartition(breastCancerFull$Class, p = .8)[[1]]
breastCancerTrain <- breastCancerFull[ inTrain, ]
breastCancerTest  <- breastCancerFull[-inTrain, ]
```
**## Build a LDA model using all features---------------------------------- **

```{r}
# Notice that we used the training set of the data to training this and the above two LDA models.
set.seed(1)
LDAFull <- train(Class ~ .,
                     data = breastCancerTrain,
                     method = "lda",
                     trControl = trainControl(method = "repeatedcv", 
                                              repeats = 5))

LDAFull
summary(LDAFull)
# Using $ sign to extract the model selected by our "trControl" procedure and print its information
LDAFull$finalModel
```

**#### Prediction on the test set -----------------------------------------------------**

```{r}
# Create prediction function that takes in a LDA model and extract some prediction information from this model on predicting test set and subsequently return these prediction information.
PredictFunc <- function(model) {
  breastCancerResults <- data.frame(obs = breastCancerTest$Class)
  breastCancerResults$prob <- predict(model, breastCancerTest, type = "prob")[, "malignant"]
  breastCancerResults$pred <- predict(model, breastCancerTest)
  breastCancerResults$Label <- ifelse(breastCancerResults$obs == "malignant", 
                              "True Outcome: malignant", 
                              "True Outcome: benign")
  return(breastCancerResults)
}

# Now use the three models that we created above to perform classification on the test set of the data. 
breastCancerResultsFull <- PredictFunc(LDAFull)
```


**#### Prediction results visualization -------------------------------------------------**

```{r probability of malignancy, fig.align='center',fig.width=9,fig.height=15}
# First, let us plot the probability of malignancy
library(gridExtra)

hist3 <- histogram(~prob|Label, data = breastCancerResultsFull, layout = c(2, 1), nint = 20, xlab = "Probability of malignancy",
          type = "count", main="LDAFull")
grid.arrange(hist3, nrow=3)

# Now, create the confusion matrix from the test set.

confusionMatrix(data = breastCancerResultsFull$pred, 
                reference = breastCancerResultsFull$obs)
```


**#########################################################################################**

# lda (Sonar) data

**#### using 10 fold cross Validation ----------------------------------------------**
```{r}

data(Sonar)
dim(Sonar)

# create cross validation folds
library(caret)
set.seed(1)
fold <- createFolds(Sonar$Class, k=10)

# apply 10-fold cross-validation

lda.TP <- lda.TN <- lda.FP <- lda.FN <- c()

for(i in 1:length(fold)){
    # true label for fold i
    truth <- Sonar$Class[fold[[i]]]
    
        # apply LDA for classification (linear discriminate analysis)
    lda.model <- lda(Class~., data=Sonar[-fold[[i]],])
    pred.probs <- predict(lda.model, newdata=Sonar[fold[[i]],-61])$posterior[,"M"]
    preds <- ifelse(pred.probs > 0.5, "M", "R")
    lda.TP <- c(lda.TP, sum((truth == preds)[truth == "M"]))
    lda.TN <- c(lda.TN, sum((truth == preds)[truth == "R"]))
    lda.FP <- c(lda.FP, sum((truth != preds)[truth == "R"]))
    lda.FN <- c(lda.FN, sum((truth != preds)[truth == "M"]))
    
}
print('')
print("lda evaluation")
evaluate(lda.TN, lda.FP, lda.TP, lda.FN)
```










