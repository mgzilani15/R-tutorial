knitr::opts_chunk$set(echo = TRUE)
# what is the optimam k value
# using k from 1 to 20 see the accuricy
predicted.purchase = NULL
accuricy.rate = NULL
for(i in 1:20){
set.seed(1)
irispred = knn(irisTrain,irisTest,iris_class_train,k=i)
accuricy.rate[i] = mean(irispred==iris_class_test)
}
# load the required library
library(class)
library(ISLR)
library(MASS)
library(caret)
# using the smarket data from ISLR LIBRARY for knn classification
# here the target variable is direction to determine whether price is moving up/down
head(Smarket)
set.seed(1)
train<-(Smarket$Year<2005)
# use the first two columns to explain the direction of smarket using cbind
smarket_train  <- cbind(Smarket$Lag1,Smarket$Lag2)[train,]
smarket_test <- cbind(Smarket$Lag1,Smarket$Lag2)[-train,]
# see the dimention of train and test
dim(smarket_train)
dim(smarket_test)
#making the class based on the train data and also see the length of it which has to be the same lenght of train data
direction=Smarket$Direction[train]
length(direction)
#  build the knn model
pred=knn(smarket_train, smarket_test, direction,k=1)
# prediction we made before is been checked with the
# actual value ofdirection.2005
direction.2005<-Smarket$Direction[-train]
table(pred,direction.2005)
# checking the accuricy where the accuricy is
# 89.91%
mean(pred==direction.2005)*100
set.seed(1)
# keeping the first 4 row which is the variable to predect the species class
iris1<-iris[,1:4]
# Test train split way-2
train=sample(1:nrow(iris1), nrow(iris1)/3)
irisTest <- iris1[train, ]
irisTrain  <- iris1[-train, ]
# dimension of train data and length
dim(irisTrain)
iris_class_train<-iris$Species[-train]
length(iris_class_train)
# building knn model
pred=knn(irisTrain, irisTest, iris_class_train,k=1)
# define test data class colum and length
iris_class_test<-iris$Species[train]
length(iris_class_test)
# confusion matrix on test data class
table(pred,iris_class_test)
# checking the accuricy where the accuricy is
# 92% good accuricy
mean(pred==iris_class_test)*100
# what is the optimam k value
# using k from 1 to 20 see the accuricy
predicted.purchase = NULL
accuricy.rate = NULL
for(i in 1:20){
set.seed(1)
irispred = knn(irisTrain,irisTest,iris_class_train,k=i)
accuricy.rate[i] = mean(irispred==iris_class_test)
}
# print the rate of accuricy for various k value
#put that in to a data frame
# print the data frame
print(accuricy.rate)
k.values <- 1:20
accuricy.df <- data.frame(accuricy.rate,k.values)
accuricy.df
# plot the accuricy rate
ggplot(accuricy.df,aes(x=k.values,y=accuricy.rate)) + geom_point()+ geom_line(lty="dotted",color='red')
set.seed(1)
train<-(Smarket$Year<2005)
# use the first two columns to explain the direction of smarket using cbind
trainsmarket  <- cbind(Smarket$Lag1,Smarket$Lag2)[train,]
testsmarket <- cbind(Smarket$Lag1,Smarket$Lag2)[-train,]
# see the dimention of train and test
dim(trainsmarket)
dim(testsmarket)
#making the class based on the train data and also see the length of it which has to be the same lenght of train data
smarket_class_train=Smarket$Direction[train]
length(smarket_class_train)
#  build the knn model
pred=knn(trainsmarket, testsmarket, smarket_class_train,k=1)
# prediction we made before is been checked with the
# actual value ofdirection.2005
direction.2005<-Smarket$Direction[-train]
table(pred,direction.2005)
# checking the accuricy where the accuricy is
# 89.91%
mean(pred==direction.2005)*100
# what is the optimam k value
# using k from 1 to 20 see the accuricy
predicted.purchase = NULL
accuricy.rate = NULL
for(i in 1:20){
set.seed(1)
smarketpred = knn(trainsmarket,testsmarket,smarket_class_train,k=i)
accuricy.rate[i] = mean(smarketpred==direction.2005)
}
# print the rate of accuricy for various k value
#put that in to a data frame
# print the data frame
print(accuricy.rate)
k.values <- 1:20
accuricy.df <- data.frame(accuricy.rate,k.values)
accuricy.df
# plot the accuricy rate iris
ggplot(accuricy.df,aes(x=k.values,y=accuricy.rate)) + geom_point()+ geom_line(lty="dotted",color='red')
# plot the accuricy rate
ggplot(accuricy.df,aes(x=k.values,y=accuricy.rate)) + geom_point()+ geom_line(lty="dotted",color='red')
set.seed(1)
library(caTools)
sample <- sample.split(final.data$Species, SplitRatio = .70)
set.seed(1)
library(caTools)
sample <- sample.split(iris$Species, SplitRatio = .70)
train <- subset(final.data, sample == TRUE)
set.seed(1)
library(caTools)
sample <- sample.split(iris$Species, SplitRatio = .70)
train <- subset(iris, sample == TRUE)
test <- subset(iris, sample == FALSE)
# spliting the iris data 70/30 split
set.seed(1)
library(caTools)
sample <- sample.split(iris$Species, SplitRatio = .70)
train <- subset(iris, sample == TRUE)
test <- subset(iris, sample == FALSE)
predicted.species <- knn(train[1:4],test[1:4],train$Species,k=1)
# spliting the iris data 70/30 split
set.seed(1)
library(caTools)
sample <- sample.split(iris$Species, SplitRatio = .70)
train <- subset(iris, sample == TRUE)
test <- subset(iris, sample == FALSE)
# predection of species in test data
prediris <- knn(train[1:4],test[1:4],train$Species,k=1)
# confusion matrix on test data class
table(prediris,test$Species)
# checking the accuricy where the accuricy is
# 92% good accuricy
mean(pred==test$Species)*100
# spliting the iris data 70/30 split
set.seed(1)
library(caTools)
sample <- sample.split(iris$Species, SplitRatio = .70)
train <- subset(iris, sample == TRUE)
test <- subset(iris, sample == FALSE)
# predection of species in test data
prediris <- knn(train[1:4],test[1:4],train$Species,k=1)
# confusion matrix on test data class
table(prediris,test$Species)
# checking the accuricy where the accuricy is
# 92% good accuricy
mean(prediris==test$Species)*100
# spliting the iris data 70/30 split
set.seed(1)
library(caTools)
sample <- sample.split(iris$Species, SplitRatio = .70)
train <- subset(iris, sample == TRUE)
test <- subset(iris, sample == FALSE)
# predection of species in test data
prediris <- knn(train[1:4],test[1:4],train$Species,k=1)
# confusion matrix on test data class
table(prediris,test$Species)
# checking the accuricy where the accuricy is
# 92% good accuricy
mean(prediris==test$Species)*100
# spliting the iris data 70/30 split
set.seed(1)
library(caTools)
sample <- sample.split(iris$Species, SplitRatio = .70)
train <- subset(iris, sample == TRUE)
test <- subset(iris, sample == FALSE)
# predection of species in test data
prediris <- knn(train[1:4],test[1:4],train$Species,k=1)
# confusion matrix on test data class
table(prediris,test$Species)
# checking the accuricy where the accuricy is
# 92% good accuricy
mean(prediris==test$Species)*100
# what is the optimam k value
# using k from 1 to 20 see the accuricy
predicted.purchase = NULL
accuricy.rate = NULL
for(i in 1:20){
set.seed(1)
irispred = knn(train,test,train$Species,k=i)
accuricy.rate[i] = mean(predirsi==test$Species)
}
# what is the optimam k value
# using k from 1 to 20 see the accuricy
predicted.purchase = NULL
accuricy.rate = NULL
for(i in 1:20){
set.seed(1)
irispred = knn(train[1:4],test[1:4],train$Species,k=i)
accuricy.rate[i] = mean(predirsi==test$Species)
}
# what is the optimam k value
# using k from 1 to 20 see the accuricy
predicted.purchase = NULL
accuricy.rate = NULL
for(i in 1:20){
set.seed(1)
irispred = knn(train[1:4],test[1:4],train$Species,k=i)
accuricy.rate[i] = mean(irispred==test$Species)
}
# print the rate of accuricy for various k value
#put that in to a data frame
# print the data frame
print(accuricy.rate)
k.values <- 1:20
accuricy.df <- data.frame(accuricy.rate,k.values)
accuricy.df
# plot the accuricy rate iris
ggplot(accuricy.df,aes(x=k.values,y=accuricy.rate)) + geom_point()+ geom_line(lty="dotted",color='red')
View(test)
View(test)
View(train)
View(train)
knitr::opts_chunk$set(echo = TRUE)
library(ISLR)
library(MASS)
library(caret)
set.seed(1)
source("functions_w6.R")
library(ISLR)
library(MASS)
library(caret)
set.seed(1)
source("functions_w6.R")
library(e1071)
library(mlbench)
library(class)
# using the smarket data from ISLR LIBRARY for knn classification
# here the target variable is direction to determine whether price is moving up/down
head(Smarket)
set.seed(1)
train<-(Smarket$Year<2005)
# use the first two columns to explain the direction of smarket using cbind
trainsmarket  <- cbind(Smarket$Lag1,Smarket$Lag2)[train,]
testsmarket <- cbind(Smarket$Lag1,Smarket$Lag2)[-train,]
# see the dimention of train and test
dim(trainsmarket)
dim(testsmarket)
#making the class based on the train data and also see the length of it which has to be the same lenght of train data
smarket_class_train=Smarket$Direction[train]
length(smarket_class_train)
#  build the knn model
pred=knn(trainsmarket, testsmarket, smarket_class_train,k=1)
# prediction we made before is been checked with the
# actual value ofdirection.2005
direction.2005<-Smarket$Direction[-train]
table(pred,direction.2005)
# checking the accuricy where the accuricy is
# 89.91%
mean(pred==direction.2005)*100
# what is the optimam k value
# using k from 1 to 20 see the accuricy
predicted.purchase = NULL
accuricy.rate = NULL
for(i in 1:20){
set.seed(1)
smarketpred = knn(trainsmarket,testsmarket,smarket_class_train,k=i)
accuricy.rate[i] = mean(smarketpred==direction.2005)
}
# print the rate of accuricy for various k value
#put that in to a data frame
# print the data frame
print(accuricy.rate)
k.values <- 1:20
accuricy.df <- data.frame(accuricy.rate,k.values)
accuricy.df
# plot the accuricy rate iris
ggplot(accuricy.df,aes(x=k.values,y=accuricy.rate)) + geom_point()+ geom_line(lty="dotted",color='red')
# structure of data file
#str(Caravan)
# summary of target variable
summary(Caravan$Purchase)
# check the null value
any(is.na(Caravan))
# example there is a variance in two variables not standard
# so need
var(Caravan[,1])
var(Caravan[,2])
# save the Purchase column in a separate variable
purchase <- Caravan[,86]
# Standarize the dataset using "scale()" R function
# using all the columns but the last/target columns
standardized.Caravan <- scale(Caravan[,-86])
# lets check again
var(standardized.Caravan[,1])
var(standardized.Caravan[,2])
# another way of test train split
# First 1000 rows for test set
test.index <- 1:1000
caravantest <- standardized.Caravan[test.index,]
caravan_test_class <- purchase[test.index]
# Rest of data for training
caravantrain <- standardized.Caravan[-test.index,]
caravan_train_class <- purchase[-test.index]
# building knn
set.seed(1)
caravanpred <- knn(caravantrain,caravantest,caravan_train_class,k=5)
# confusion matrix on test data class
table(caravanpred,caravan_test_class)
# checking the accuricy where the accuricy is
# 88.2% good accuricy
mean(caravanpred==caravan_test_class)*100
# what is the optimam k value
# using k from 1 to 20 see the accuricy
predicted.purchase = NULL
accuricy.rate = NULL
for(i in 1:20){
set.seed(1)
caravanpred = knn(caravantrain,caravantest,caravan_train_class,k=i)
accuricy.rate[i] = mean(caravanpred==caravan_test_class)
}
# print the rate of accuricy for various k value
#put that in to a data frame
# print the data frame
print(accuricy.rate)
k.values <- 1:20
accuricy.df <- data.frame(accuricy.rate,k.values)
accuricy.df
# plot the accuricy rate
ggplot(accuricy.df,aes(x=k.values,y=accuricy.rate)) + geom_point()+ geom_line(lty="dotted",color='red')
set.seed(1)
train<-(Smarket$Year<2005)
# use the first two columns to explain the direction of smarket using cbind
trainsmarket  <- cbind(Smarket$Lag1,Smarket$Lag2)[train,]
testsmarket <- cbind(Smarket$Lag1,Smarket$Lag2)[-train,]
# see the dimention of train and test
dim(trainsmarket)
dim(testsmarket)
#making the class based on the train data and also see the length of it which has to be the same lenght of train data
smarket_class_train=Smarket$Direction[train]
length(smarket_class_train)
#  build the knn model
pred=knn(trainsmarket, testsmarket, smarket_class_train,k=3)
# spliting the iris data 70/30 split
set.seed(1)
library(caTools)
sample <- sample.split(iris$Species, SplitRatio = .70)
train <- subset(iris, sample == TRUE)
test <- subset(iris, sample == FALSE)
# length and dim of some important things
dim(train)
dim(test)
length(train$Species)
# predection of species in test data
prediris <- knn(train[1:4],test[1:4],train$Species,k=4)
# confusion matrix on test data class
table(prediris,test$Species)
# checking the accuricy where the accuricy is
# 92% good accuricy
accuricy<-mean(prediris==test$Species)*100
print(paste('Accuricy is-----', accuricy, '%'))
# what is the optimam k value
# using k from 1 to 20 see the accuricy
predicted.purchase = NULL
accuricy.rate = NULL
for(i in 1:20){
set.seed(1)
irispred = knn(train[1:4],test[1:4],train$Species,k=i)
accuricy.rate[i] = mean(irispred==test$Species)
}
# print the rate of accuricy for various k value
#put that in to a data frame
# print the data frame
print(accuricy.rate)
k.values <- 1:20
accuricy.df <- data.frame(accuricy.rate,k.values)
accuricy.df
# plot the accuricy rate iris
ggplot(accuricy.df,aes(x=k.values,y=accuricy.rate)) + geom_point()+ geom_line(lty="dotted",color='red')
data(Sonar)
dim(Sonar)
# create cross validation folds
library(caret)
set.seed(1)
fold <- createFolds(Sonar$Class, k=10)
# apply 10-fold cross-validation
knn.TP <- knn.TN <- knn.FP <- knn.FN <- c()
lda.TP <- lda.TN <- lda.FP <- lda.FN <- c()
glm.TP <- glm.TN <- glm.FP <- glm.FN <- c()
svm.line.TP <- svm.line.TN <- svm.line.FP <- svm.line.FN <- c()
for(i in 1:length(fold)){
# true label for fold i
truth <- Sonar$Class[fold[[i]]]
# apply knn for classification
preds <- knn(Sonar[-fold[[i]],-61], Sonar[fold[[i]],-61], Sonar$Class[-fold[[i]]], k=5)
knn.TP <- c(knn.TP, sum((truth == preds)[truth == "M"]))
knn.TN <- c(knn.TN, sum((truth == preds)[truth == "R"]))
knn.FP <- c(knn.FP, sum((truth != preds)[truth == "R"]))
knn.FN <- c(knn.FN, sum((truth != preds)[truth == "M"]))
}
print("knn evaluation")
evaluate(knn.TN, knn.FP, knn.TP, knn.FN)
data(Ionosphere)
df <- Ionosphere
df <- df[,-2]
df <- df[,-1]
# apply 10-fold cross-validation
fold <- createFolds(df$Class, k=10)
knn.TP <- knn.TN <- knn.FP <- knn.FN <- c()
for(i in 1:length(fold)){
# true label for fold i
truth <- df$Class[fold[[i]]]
# apply knn for classification
preds <- knn(df[-fold[[i]],-33], df[fold[[i]],-33], df$Class[-fold[[i]]], k=5)
knn.TP <- c(knn.TP, sum((truth == preds)[truth == "M"]))
knn.TN <- c(knn.TN, sum((truth == preds)[truth == "R"]))
knn.FP <- c(knn.FP, sum((truth != preds)[truth == "R"]))
knn.FN <- c(knn.FN, sum((truth != preds)[truth == "M"]))
}
print("knn evaluation")
evaluate(knn.TN, knn.FP, knn.TP, knn.FN)
data(Ionosphere)
df <- Ionosphere
df <- df[,-2]
df <- df[,-1]
# apply 10-fold cross-validation
fold <- createFolds(df$Class, k=10)
knn.TP <- knn.TN <- knn.FP <- knn.FN <- c()
for(i in 1:length(fold)){
# true label for fold i
truth <- df$Class[fold[[i]]]
# apply knn for classification
preds <- knn(df[-fold[[i]],-33], df[fold[[i]],-33], df$Class[-fold[[i]]], k=5)
knn.TP <- c(knn.TP, sum((truth == preds)[truth == "good"]))
knn.TN <- c(knn.TN, sum((truth == preds)[truth == "bad"]))
knn.FP <- c(knn.FP, sum((truth != preds)[truth == "bad"]))
knn.FN <- c(knn.FN, sum((truth != preds)[truth == "good"]))
}
print("knn evaluation")
evaluate(knn.TN, knn.FP, knn.TP, knn.FN)
