library(tree)
library(MASS)
library(caTools)
library(ISLR)
library(rpart)
#install packages and get the data set Boston
library(randomForest)
library(tree)
library(MASS)
data=Boston
head(Boston)
dim(data)
#str(data)
str(data)
# in this case we use medv as our target variable and the problem is define as a regression problem
# first make the decision tree without using test/train split
# boston is having 14 variable all neumeric
dt<-tree(medv~., data=data)
# summary of the tree
summary(dt)
# we can see that this is a single tree 5 predector been randomly used to make the model
# but the error in the residual is 13.55
# which we will compare in our other model later
# plot and text the dt
plot(dt)
text(dt)
# here we use same kind of formula but used 6 variables as predector
# but in here error is 9.80
# which is better than decision tree
# default number of tree is 500
rf<-randomForest(medv~., data=data, mtray=6)
rf
# ploting the random forest
plot(rf)
# here we use same kind of formula but used all (13) variables as predector
# this is bagging because using all the variables, except the predector
# but in here error is 9.75
# which is better than decision tree
# default number of tree is 500
btree<-randomForest(medv~., data=data, mtray=13)
btree
# ploting the bagging tree
plot(btree)
#Split your data into training and testing sets 70/30. Use the caTools library to do this.
#library(caTools)
set.seed(101)
sample = sample.split(data$medv, SplitRatio = .70)
train = subset(data, sample == TRUE)
test = subset(data, sample == FALSE)
dim(test)
dim(train)
# build the model using the train data
#library(rpart)
dt<- tree(medv ~.,data = train)
# summary of the tree using train data
summary(dt)
# ploting the tree
plot(dt)
text(dt, pretty=0)
# cross validation of the tree
cv_dt=cv.tree(dt)
plot(cv_dt$size,cv_dt$dev, type="b")
# use the test data to prediction
dt.preds <- predict(dt,test)
#dt.preds
summary(dt.preds)
# install library ISLR
# using the carseats data file
library(ISLR)
attach(Carseats)
library(randomForest)
head(Carseats)
# see the dimansion of the Carseats data file
# there are 400 observation with 11 variables, sales is the target variable and the rest are the
# exploratory variables
# it seems this is a regration problem while the sale data is a continious variable
# we gonn apredict the sale
dim(Carseats)
#Split your data into training and testing sets 70/30. Use the caTools library to do this.
library(caTools)
set.seed(101)
sample = sample.split(Carseats$Sales, SplitRatio = .70)
train = subset(Carseats, sample == TRUE)
test = subset(Carseats, sample == FALSE)
dim(train)
dim(test)
# inorder to see the performance of bagging model lets build a model in decision tree
# after than we will compare the performance of bagging model with the decission tree.
# our decision tree model is :
library(rpart)
library(tree)
# based on the regression problem using the carsales data making the model
dt <- tree(Sales ~.,data = train)
summary(dt)
# use the test data to prediction
tree.preds <- predict(dt,test)
# plot the predection vs the sales
plot(tree.preds, test$Sales)
# calculate the RMSE is the test error from the data set
mean((tree.preds-test$Sales)^2)
# PLOTING A LINE
abline(0,1)
# now lets see if the bagging is improving the test error
# number of tree is 500 here, though bydefault system took 3 variables to make the model
#we can define it by using mtry=6 (mean use 6 variables) which we can see belowing the RMSE
rf.model <- randomForest(Sales ~ . , data = train, ntree=500, mtry=4, importance = TRUE)
#What was your model's confusion matrix on its own training set? Use model$confusion.
rf.model$confusion
# print the model in train data
rf.model
# after we see the model there are 3 variables been used and 500 tree been built
#Now use your random forest model to predict on your test set!
p <- predict(rf.model,test)
# plotting sales verses the others
plot(p,test$Sales)
abline(0,1)
#p
# calculate the RMSE is the test error from the data set
mean((p-test$Sales)^2)
# discussion: this is much better fit than the decision tree we saw before, and the RMSE(ROOT MEAN SQUIRE ERROR)
# is very less in here than before, which mean this is better model selection for this data set
#AS we mentioned the importance = true in our model
# below is the importancy of all the variables
rf.model$importance
# Assending order of the variables importancy
varImpPlot(rf.model)
# getting data file
# college data set is in ISLR library
df<-College
head(df)
#Split your data into training and testing sets 70/30. Use the caTools library to do this.
set.seed(101)
sample = sample.split(df$Private, SplitRatio = .70)
train = subset(df, sample == TRUE)
test = subset(df, sample == FALSE)
#Use the rpart library to build a decision tree to predict whether or not a school is Private. Remember to only build your tree off the training data.
# build the tree on training data based on the private as a classifier
library(tree)
dt <- tree(Private ~.,data = train)
summary(dt)
# use the test data to prediction
tree.preds <- predict(dt,test)
#Check the Head of the predicted values. You should notice that you actually have two columns with the probabilities.
head(tree.preds)
#Use the rpart.plot library and the prp() function to plot out your tree model.
library(tree)
plot(dt)
text(dt, pretty=0)
#Now use randomForest() to build out a model to predict Private class. Add importance=TRUE as a parameter in the model. (Use help(randomForest) to find out what this does.
rf.model <- randomForest(Private ~ . , data = train,importance = TRUE)
# print the model
rf.model
#AS we mentioned the importance = true in our model
# below is the importancy of all the variables
rf.model$importance
# Assending order of the variables importancy
varImpPlot(rf.model)
library(pROC)
#Now use your random forest model to predict on your test set!
p <- predict(rf.model,test)
# making the confussion matrix
t=table(predictions=p,actual=test$Private)
t
# accurity rate
sum(diag(t))/sum(t)
# PREDECTION WITH PROBABILITY
predectionwithprob<-predict(rf.model,test,type='prob')
plot(roc(test$Private,predectionwithprob[,2]))
df<-birthwt
str(df)
df[,c('low','race', 'smoke','ptl','ht', 'ui','ftv')] <- lapply(df[,c('low','race', 'smoke','ptl','ht', 'ui','ftv')],as.factor)
str(df)
#Split your data into training and testing sets 70/30. Use the caTools library to do this.
set.seed(101)
sample = sample.split(df$low, SplitRatio = .70)
train = subset(df, sample == TRUE)
test = subset(df, sample == FALSE)
str(train)
dt <-tree(low ~.,data = train)
summary(dt)
#Now use randomForest() to build out a model to predict Private class. Add importance=TRUE as a parameter in the model. (Use help(randomForest) to find out what this does.
rf.model <- randomForest(low ~ . , data = train,importance = TRUE,mtray=3, ntree=20)
# print the model
rf.model
#AS we mentioned the importance = true in our model
# below is the importancy of all the variables
rf.model$importance
# Assending order of the variables importancy
varImpPlot(rf.model)
library(pROC)
#Now use your random forest model to predict on your test set!
p <- predict(rf.model,test)
# making the confussion matrix
t=table(predictions=p,actual=test$low)
t
# accurity rate
sum(diag(t))/sum(t)
# PREDECTION WITH PROBABILITY
predectionwithprob<-predict(rf.model,test,type='prob')
plot(roc(test$low,predectionwithprob[,2]))
df<-birthwt
str(df)
df[,c('low','race', 'smoke','ptl','ht', 'ui','ftv')] <- lapply(df[,c('low','race', 'smoke','ptl','ht', 'ui','ftv')],as.factor)
str(df)
#Split your data into training and testing sets 70/30. Use the caTools library to do this.
set.seed(101)
sample = sample.split(df$low, SplitRatio = .70)
train = subset(df, sample == TRUE)
test = subset(df, sample == FALSE)
df<-birthwt
str(df)
#df[,c('low','race', 'smoke','ptl','ht', 'ui','ftv')] <- lapply(df[,c('low','race', 'smoke','ptl','ht', 'ui','ftv')],as.factor)
str(df)
#Split your data into training and testing sets 70/30. Use the caTools library to do this.
set.seed(101)
sample = sample.split(df$low, SplitRatio = .70)
train = subset(df, sample == TRUE)
test = subset(df, sample == FALSE)
str(train)
dt <-tree(low ~.,data = train)
summary(dt)
#Now use randomForest() to build out a model to predict Private class. Add importance=TRUE as a parameter in the model. (Use help(randomForest) to find out what this does.
rf.model <- randomForest(low ~ . , data = train,importance = TRUE,mtray=3, ntree=20)
# print the model
rf.model
#Now use randomForest() to build out a model to predict Private class. Add importance=TRUE as a parameter in the model. (Use help(randomForest) to find out what this does.
rf.model <- randomForest(low ~ . , data = train,importance = TRUE,mtray=3, ntree=20)
# print the model
rf.model
#Now use randomForest() to build out a model to predict Private class. Add importance=TRUE as a parameter in the model. (Use help(randomForest) to find out what this does.
rf.model <- randomForest(low ~ . , data = train,importance = TRUE,mtray=3, ntree=20)
# print the model
rf.model
#Now use randomForest() to build out a model to predict Private class. Add importance=TRUE as a parameter in the model. (Use help(randomForest) to find out what this does.
rf.model <- randomForest(low ~ . , data = train,mtray=3, ntree=20)
# print the model
rf.model
#AS we mentioned the importance = true in our model
# below is the importancy of all the variables
rf.model$importance
# Assending order of the variables importancy
varImpPlot(rf.model)
library(pROC)
#Now use your random forest model to predict on your test set!
p <- predict(rf.model,test)
# making the confussion matrix
t=table(predictions=p,actual=test$low)
t
# accurity rate
sum(diag(t))/sum(t)
# PREDECTION WITH PROBABILITY
predectionwithprob<-predict(rf.model,test,type='prob')
df<-birthwt
str(df)
df[,c('low','race', 'smoke','ptl','ht', 'ui','ftv')] <- lapply(df[,c('low','race', 'smoke','ptl','ht', 'ui','ftv')],as.factor)
str(df)
#Split your data into training and testing sets 70/30. Use the caTools library to do this.
set.seed(101)
sample = sample.split(df$low, SplitRatio = .70)
train = subset(df, sample == TRUE)
test = subset(df, sample == FALSE)
str(train)
dt <-tree(low ~.,data = train)
summary(dt)
#Now use randomForest() to build out a model to predict Private class. Add importance=TRUE as a parameter in the model. (Use help(randomForest) to find out what this does.
rf.model <- randomForest(low ~ . , data = train,mtray=3, ntree=20)
# print the model
rf.model
#AS we mentioned the importance = true in our model
# below is the importancy of all the variables
rf.model$importance
# Assending order of the variables importancy
varImpPlot(rf.model)
library(pROC)
#Now use your random forest model to predict on your test set!
p <- predict(rf.model,test)
# making the confussion matrix
t=table(predictions=p,actual=test$low)
t
# accurity rate
sum(diag(t))/sum(t)
# PREDECTION WITH PROBABILITY
predectionwithprob<-predict(rf.model,test,type='prob')
plot(roc(test$low,predectionwithprob[,2]))
library(randomForest)
library(tree)
library(MASS)
library(caTools)
library(ISLR)
library(rpart)
library(randomForest)
library(tree)
library(MASS)
library(caTools)
library(ISLR)
library(rpart)
#install packages and get the data set Boston
library(randomForest)
library(tree)
library(MASS)
data=Boston
head(Boston)
dim(data)
#str(data)
str(data)
# in this case we use medv as our target variable and the problem is define as a regression problem
# first make the decision tree without using test/train split
# boston is having 14 variable all neumeric
dt<-tree(medv~., data=data)
# summary of the tree
summary(dt)
# we can see that this is a single tree 5 predector been randomly used to make the model
# but the error in the residual is 13.55
# which we will compare in our other model later
# plot and text the dt
plot(dt)
text(dt)
# here we use same kind of formula but used 6 variables as predector
# but in here error is 9.80
# which is better than decision tree
# default number of tree is 500
rf<-randomForest(medv~., data=data, mtray=6)
rf
# ploting the random forest
plot(rf)
# here we use same kind of formula but used all (13) variables as predector
# this is bagging because using all the variables, except the predector
# but in here error is 9.75
# which is better than decision tree
# default number of tree is 500
btree<-randomForest(medv~., data=data, mtray=13)
btree
# ploting the bagging tree
plot(btree)
#Split your data into training and testing sets 70/30. Use the caTools library to do this.
#library(caTools)
set.seed(101)
sample = sample.split(data$medv, SplitRatio = .70)
train = subset(data, sample == TRUE)
test = subset(data, sample == FALSE)
dim(test)
dim(train)
# build the model using the train data
#library(rpart)
dt<- tree(medv ~.,data = train)
# summary of the tree using train data
summary(dt)
# ploting the tree
plot(dt)
text(dt, pretty=0)
# cross validation of the tree
cv_dt=cv.tree(dt)
plot(cv_dt$size,cv_dt$dev, type="b")
# use the test data to prediction
dt.preds <- predict(dt,test)
#dt.preds
summary(dt.preds)
# install library ISLR
# using the carseats data file
library(ISLR)
attach(Carseats)
library(randomForest)
head(Carseats)
# see the dimansion of the Carseats data file
# there are 400 observation with 11 variables, sales is the target variable and the rest are the
# exploratory variables
# it seems this is a regration problem while the sale data is a continious variable
# we gonn apredict the sale
dim(Carseats)
# see the dimansion of the Carseats data file
# there are 400 observation with 11 variables, sales is the target variable and the rest are the
# exploratory variables
# it seems this is a regration problem while the sale data is a continious variable
# we gonn apredict the sale
dim(Carseats)
str(Carseat)
# see the dimansion of the Carseats data file
# there are 400 observation with 11 variables, sales is the target variable and the rest are the
# exploratory variables
# it seems this is a regration problem while the sale data is a continious variable
# we gonn apredict the sale
dim(Carseats)
str(Carseats)
#Split your data into training and testing sets 70/30. Use the caTools library to do this.
library(caTools)
set.seed(101)
sample = sample.split(Carseats$Sales, SplitRatio = .70)
train = subset(Carseats, sample == TRUE)
test = subset(Carseats, sample == FALSE)
dim(train)
dim(test)
# inorder to see the performance of bagging model lets build a model in decision tree
# after than we will compare the performance of bagging model with the decission tree.
# our decision tree model is :
library(rpart)
library(tree)
# based on the regression problem using the carsales data making the model
dt <- tree(Sales ~.,data = train)
summary(dt)
# use the test data to prediction
tree.preds <- predict(dt,test)
# plot the predection vs the sales
plot(tree.preds, test$Sales)
# calculate the RMSE is the test error from the data set
mean((tree.preds-test$Sales)^2)
# PLOTING A LINE
abline(0,1)
# now lets see if the bagging is improving the test error
# number of tree is 500 here, though bydefault system took 3 variables to make the model
#we can define it by using mtry=6 (mean use 6 variables) which we can see belowing the RMSE
rf.model <- randomForest(Sales ~ . , data = train, ntree=500, mtry=4, importance = TRUE)
#What was your model's confusion matrix on its own training set? Use model$confusion.
rf.model$confusion
# print the model in train data
rf.model
# after we see the model there are 3 variables been used and 500 tree been built
#Now use your random forest model to predict on your test set!
p <- predict(rf.model,test)
# plotting sales verses the others
plot(p,test$Sales)
abline(0,1)
#p
# calculate the RMSE is the test error from the data set
mean((p-test$Sales)^2)
# discussion: this is much better fit than the decision tree we saw before, and the RMSE(ROOT MEAN SQUIRE ERROR)
# is very less in here than before, which mean this is better model selection for this data set
#Now use your random forest model to predict on your test set!
p <- predict(rf.model,test)
# plotting sales verses the others
plot(p,test$Sales)
abline(0,1)
#p
# calculate the RMSE is the test error from the data set
mean((p-test$Sales)^2)
# discussion: this is much better fit than the decision tree we saw before, and the RMSE(ROOT MEAN SQUIRE ERROR)
# is very less in here than before, which mean this is better model selection for this data set
#AS we mentioned the importance = true in our model
# below is the importancy of all the variables
rf.model$importance
# Assending order of the variables importancy
varImpPlot(rf.model)
# in this case we use medv as our target variable and the problem is define as a regression problem
# first make the decision tree without using test/train split
# boston is having 14 variable all neumeric
dt<-tree(medv~., data=data)
# summary of the tree
summary(dt)
# we can see that this is a single tree 5 predector been randomly used to make the model
# but the error in the residual is 13.55
# which we will compare in our other model later
# plot and text the dt
plot(dt)
text(dt)
library(randomForest)
library(tree)
library(MASS)
library(caTools)
library(ISLR)
library(rpart)
#install packages and get the data set Boston
library(randomForest)
library(tree)
library(MASS)
data=Boston
head(Boston)
dim(data)
#str(data)
# in this case we use medv as our target variable and the problem is define as a regression problem
# first make the decision tree without using test/train split
# boston is having 14 variable all neumeric
dt<-tree(medv~., data=data)
# summary of the tree
summary(dt)
# we can see that this is a single tree 5 predector been randomly used to make the model
# but the error in the residual is 13.55
# which we will compare in our other model later
# plot and text the dt
plot(dt)
text(dt)
# in this case we use medv as our target variable and the problem is define as a regression problem
# first make the decision tree without using test/train split
# boston is having 14 variable all neumeric
dt<-rpart(medv~., data=data)
# summary of the tree
summary(dt)
# we can see that this is a single tree 5 predector been randomly used to make the model
# but the error in the residual is 13.55
# which we will compare in our other model later
# plot and text the dt
plot(dt)
text(dt)
# in this case we use medv as our target variable and the problem is define as a regression problem
# first make the decision tree without using test/train split
# boston is having 14 variable all neumeric
dt<-tree(medv~., data=data)
# summary of the tree
summary(dt)
# we can see that this is a single tree 5 predector been randomly used to make the model
# but the error in the residual is 13.55
# which we will compare in our other model later
# plot and text the dt
plot(dt)
text(dt)
# here we use same kind of formula but used all (13) variables as predector
# this is bagging because using all the variables, except the predector
# but in here error is 9.75
# which is better than decision tree
# default number of tree is 500
btree<-randomForest(medv~., data=data, mtray=13)
btree
# ploting the bagging tree
plot(btree)
